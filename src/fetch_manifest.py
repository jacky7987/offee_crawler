from fetch_page import fetch_page
from fetch_sitemap import fetch_sitemap_text, parse_sitemap_xml, filter_product_urls

def fetch_all_pages(sitemap_url: str, brand_name: str = None, save_html:bool=False):
    """
    æ ¹æ“š sitemap URL æŠ“å–è©²ç¶²ç«™æ‰€æœ‰å•†å“é  HTMLã€‚
    Args:
        sitemap_url (str): è©²ç¶²ç«™çš„ sitemap.xml ä½ç½®
        brand_name (str, optional): å“ç‰Œåç¨±ï¼ˆå¯é¸ï¼Œç”¨æ–¼æª”åæˆ–æ—¥èªŒï¼‰
    """
    sitemap__text = fetch_sitemap_text(sitemap_url)
    urls = parse_sitemap_xml(sitemap__text)
    product_urls = filter_product_urls(urls)

    print(f"ğŸ” Found {len(product_urls)} product pages from {brand_name or sitemap_url}")

    if not save_html:
        return product_urls

    path_list = []

    for url in product_urls:
        try:
            path = fetch_page(url, save_html)
            path_list.append(path)
            print(f"âœ… Saved: {path}")
        except Exception as e:
            print(f"âŒ Failed: {url} ({e})")
    
    return path_list